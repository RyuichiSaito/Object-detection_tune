{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeyunxoaK34ngGzBRykv2K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyuichiSaito/Object-detection_tune/blob/yolov7/yolov7/yolo_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yoloの転移学習**\n",
        "\n",
        "# 1.各種インポート\n",
        "\n",
        "[![WongKinYiu/yolov7 - GitHub](https://gh-card.dev/repos/WongKinYiu/yolov7.svg)](https://github.com/WongKinYiu/yolov7)"
      ],
      "metadata": {
        "id": "8uJdvCWFV44k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbM3GiqvXq9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "255a5362-d866-4f4d-e806-6376a44a0c67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1094, done.\u001b[K\n",
            "remote: Total 1094 (delta 0), reused 0 (delta 0), pack-reused 1094\u001b[K\n",
            "Receiving objects: 100% (1094/1094), 69.89 MiB | 39.28 MiB/s, done.\n",
            "Resolving deltas: 100% (516/516), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.0+cu116)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (6.0)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "!pip install torchvision\n",
        "!pip install PyYAML"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練済みモデルをDLする\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt -P ./yolov7/checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vB3kv_KWNYC",
        "outputId": "29cb6bf5-1ec0-48a0-b3f8-4885a662171d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-26 01:36:37--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ba7d01ee-125a-4134-8864-fa1abcbf94d5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221226%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221226T013637Z&X-Amz-Expires=300&X-Amz-Signature=0ccfa9ac6f6c2aa46fa4398fce159dd4b691a8e2cf4ece7e112c1de01c37ae77&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-tiny.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-26 01:36:37--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ba7d01ee-125a-4134-8864-fa1abcbf94d5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221226%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221226T013637Z&X-Amz-Expires=300&X-Amz-Signature=0ccfa9ac6f6c2aa46fa4398fce159dd4b691a8e2cf4ece7e112c1de01c37ae77&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-tiny.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12639769 (12M) [application/octet-stream]\n",
            "Saving to: ‘./yolov7/checkpoints/yolov7-tiny.pt’\n",
            "\n",
            "yolov7-tiny.pt      100%[===================>]  12.05M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-12-26 01:36:37 (202 MB/s) - ‘./yolov7/checkpoints/yolov7-tiny.pt’ saved [12639769/12639769]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wandbを使用する場合 (Optional)\n",
        "\n",
        "* wandbとは？\n",
        "\n",
        "> W&B (Weights & Biases)は、機械学習実験、デバッグ、可視化のためのツール\n",
        "　次のような機能がある\n",
        "　\n",
        "　\n",
        "* 自動ログ記録：W&Bは、実験に関する広範なデータ（コード、ハイパーパラメータ、メトリック、アーティファクト（モデルの重みや予測など）など）自動的にログに記録する\n",
        "* インタラクティブな可視化：W&Bは、異なる実験の結果を探索し比較するのを容易にするインタラクティブな可視化が可能\n",
        "* 共同作業：W&Bを使用すると、実験と結果を他の人と共有できるため、チームメンバーとの共同作業や結果のレビューが容易になる\n",
        "\n",
        "* 使い方\n",
        "\n",
        "1.   アカウントを作成する\n",
        " \n",
        "  https://wandb.ai/site\n",
        "\n",
        "  [![Weights & Biases](https://embed.zenn.studio/api/optimize-og-image/c241bb602ba8ae73885f/https%3A%2F%2Fi.imgur.com%2F1sm6x8P.png)](https://wandb.ai/site)\n",
        "\n",
        "\n",
        "2.   ログインする \n",
        "\n",
        "    https://wandb.ai/authorize に表示されるキーを入力する\n",
        "\n"
      ],
      "metadata": {
        "id": "s3f1IvpXWttd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "k7I1L7zCnMaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://wandb.ai/authorize に表示されるキーを入力する\n",
        "!wandb login"
      ],
      "metadata": {
        "id": "foRLyN2anP-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project=\"yolov7-meta\", entity=\"ryu10\") # https://docs.wandb.ai/ref/python/init "
      ],
      "metadata": {
        "id": "Wks8J5mJWgQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 2.学習の準備\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### コードの調整\n",
        "\n",
        "  次の変更が必要（何故かエラーになる）\n",
        "\n",
        "1.  \n",
        "  ``` python \n",
        "  # utils/loss.py 759行目\n",
        "\n",
        "  #from_which_layer = from_which_layer[fg_mask_inboxes]\n",
        "  from_which_layer = from_which_layer[fg_mask_inboxes.to('cpu')]\n",
        "  ```\n",
        "2.   \n",
        "  ``` python \n",
        "# util/google_util.py 25～27行目\n",
        "\n",
        "    # response = requests.get(f'https://api.github.com/repos/{repo}/releases/latest').json()  # github api\n",
        "    assets =  ['yolov7.pt', 'yolov7-tiny.pt', 'yolov7x.pt', 'yolov7-d6.pt', 'yolov7-e6.pt', \n",
        "              'yolov7-e6e.pt', 'yolov7-w6.pt']#[x['name'] for x in response['assets']]  # release assets\n",
        "    tag = 'v0.1'#response['tag_name']  # i.e. 'v1.0'\n",
        "  ```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "また、画像の前処理を変更したい場合、次の変更が必要\n",
        "\n",
        "例）モルフォロジー変換した情報を入れる場合\n",
        "``` python \n",
        "# util/datasets.py 186, 670 \n",
        "\n",
        "# img0 = cv2.imread(path)\n",
        "\n",
        "img0_ = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "kernel1 = np.ones((30, 30), np.uint8)\n",
        "kernel2 = np.ones((1, 75), np.uint8)\n",
        "\n",
        "img0 = np.stack((img0_, ) * 3, axis=-1)\n",
        "img0[:,:,1] = cv2.erode(img0_, kernel1, iterations=1)\n",
        "img0[:,:,2] = cv2.erode(img0_, kernel2, iterations=1)\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 学習データの準備\n",
        "\n",
        "* GoogleDrive か Colabのランタイム上 に学習データ(image + xml)をアップロードする．\n",
        "\n",
        "ファイル\n",
        "\n",
        "```\n",
        "┠ data\n",
        "     ┠ train\n",
        "     ┃   ┠ images\n",
        "     ┃   ┃   ┗ *.jpg\n",
        "     ┃   ┗ labels\n",
        "     ┃       ┠ classes.txt\n",
        "     ┃       ┗ *.txt\n",
        "     ┠ val\n",
        "         ┗ images\n",
        "             ┗ *.jpg\n",
        "```\n",
        "\n",
        "```\n",
        "# classes.txt\n",
        "link\n",
        "lotnum\n",
        "box\n",
        "```"
      ],
      "metadata": {
        "id": "nM11dpE-dwOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# 3.学習の実行\n",
        "\n",
        "次のコマンドで転移学習を行う\n",
        "```\n",
        "!python yolov7/train.py \\ #以下各種オプション\n",
        "  --weights yolov7/cfg/training/yolov7-tiny.yaml \\\n",
        "  --cfg yolov7/cfg/training/yolov7-tiny.yaml \\\n",
        "  --hyp '～/hyp.scratch.tiny.yaml' \\\n",
        "  --data '～/ocr_model.yaml' \\\n",
        "                  ：\n",
        "                  ： \n",
        "```\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "各オプションの解説： 詳しくは、[この記事を参照](https://qiita.com/shinya_sun_sun/items/8c368f3024bf5b0d14aa#--evolve-%E9%81%BA%E4%BC%9D%E6%95%B0)\n",
        "\n",
        "| オプション  | 説明 | デフォルト値 |必要かどうか | \n",
        "| ------      | -------- | ---- | ---- |\n",
        "| weights       | 転移学習するweightsのパス | yolo7.pt | ○ | \n",
        "| cfg           | モデル構成ファイルのパス | model.yaml path | ○ | \n",
        "| data          | データセットのパス（任意のパス） | data/coco.yaml | ○ | \n",
        "| hyp           | ハイパーパラメータのパス（任意のパス） | data/hyp.scratch.p5.yaml | ○ | \n",
        "| epochs        | 学習エポック数 | 300 | ○ | \n",
        "| batch-size    | バッチサイズ | 16 | △ | \n",
        "| img-size      | 画像のサイズ(height, width) | [640, 640] | ○ | \n",
        "| rect          | 長方形画像での学習 | False |  | \n",
        "| resume        | 学習の再開を指定 | False |  | \n",
        "| nosave        | 最終エポックだけを保存 | False |  | \n",
        "| notest        | 最終エポックだけを検証 | False |  | \n",
        "| noautoanchor  | オートアンカーを無効 | False |  | \n",
        "| evolve        | ハイパーパラメータの遺伝、および、遺伝数を指定 | False |  | \n",
        "| bucket        | Google Cloud Storageのバケット名称 |  |  | \n",
        "| cache-images  | 画像をキャッシュするか（学習の高速化） | False | △ | \n",
        "| image-weights | 学習時に読み込まれる画像が加重選択されるよう指定 | False |  | \n",
        "| device        | デバイスを指定 | '' | ○ | \n",
        "| multi-scale   |学習時の画像サイズを+/- 50%範囲でランダムにスケール|False |  | \n",
        "| single-cls    |複数クラスを持つデータセットを単一クラスのデータとして学習 | False |  | \n",
        "| adam          | OptimizerにAdamを使うか | False (SGD) |  | \n",
        "| sync-bn       | マルチGPU学習時にバッチ正則化の値を統一するか | False |  | \n",
        "| local_rank    |ノード内で何番目のプロセスかを指定| -1(変更不可)  | | \n",
        "| workers       | データローダーに使用するCPU個数の最大値 | 8 |  | \n",
        "| project       | プロジェクトフォルダ | runs/train |  | \n",
        "| entity        | W&B entity | None |  | \n",
        "| name          | 学習結果を保存するフォルダ | exp |  | \n",
        "| exist-ok      |`--name`で指定されたフォルダに学習結果を上書きする| False |  | \n",
        "| quad          | クアッドデータローダ | False |  | \n",
        "| linear-lr     | 学習率変化(linearLR)を使うか | False |  | \n",
        "| label-smoothing| ラベルの平滑化を行うか | False |  | \n",
        "| upload_dataset|  +  | False |  | \n",
        "| bbox_interval |  +  | False |  | \n",
        "| save_period   |  +  | False |  | \n",
        "| artifact_alias|  +  | False |  | \n",
        "| freeze        | モデル内の固定する層を指定 | [0] |  | \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### data yamlについて\n",
        "\n",
        "``` yaml\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: /content/drive/～/train # trainフォルダのパス\n",
        "val: /content/drive/～/val # valフォルダパス\n",
        "\n",
        "# number of classes\n",
        "nc: 3 # boxが不要な場合，2\n",
        "\n",
        "# class names\n",
        "names: ['link', 'lotnum', 'box'] # ['link', 'lotnum'] boxが不要な場合\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### hyp yamlについて \n",
        "詳しくは、[この記事を参照](https://medium.com/augmented-startups/how-hyperparameters-of-yolov5-works-ec4d25f311a2)\n",
        "\n",
        "| オプション  | 説明     | デフォルト値 |\n",
        "| ------      | -------- | ----         | \n",
        "| lr0            | initial learning rate | 0.01  | \n",
        "| lrf            | final OneCycleLR learning rate | 0.01  | \n",
        "| momentum       | SGD momentum/Adam beta1 | 0.937 | \n",
        "| weight_decay   | optimizer weight decay 5e-4 | 0.0005 | \n",
        "| warmup_epochs  | warmup epochs (fractions ok) | 3.0 | \n",
        "| warmup_momentum| warmup initial momentum | 0.8 | \n",
        "| warmup_bias_lr | warmup initial bias lr | 0.1 | \n",
        "| box            | box loss gain | 0.05 | \n",
        "| cls            | cls loss gain | 0.5 | \n",
        "| cls_pw         | cls BCELoss positive_weight | 1.0 | \n",
        "| obj            | obj loss gain (scale with pixels) | 1.0 | \n",
        "| obj_pw         | obj BCELoss positive_weight | 1.0 | \n",
        "| iou_t          | IoU training threshold | 0.20 | \n",
        "| anchor_t       | anchor-multiple threshold | 4.0 | \n",
        "| fl_gamma       | [Focal Loss](https://qiita.com/agatan/items/53fe8d21f2147b0ac982) gamma (efficientDet default gamma=1.5) | 0.0 | \n",
        " ⇓⇓⇓ ここからがデータ拡張 ⇓⇓⇓\n",
        "| hsv_h          | image HSV-Hue augmentation (fraction)  | 0.0 | \n",
        "| hsv_s          | image HSV-Saturation augmentation (fraction) | 0.0 | \n",
        "| hsv_v          | image HSV-Value augmentation (fraction) | 0.0 | \n",
        "| degrees        | ランダムに画像を回転させる確率 | 0.0 | \n",
        "| translate      | ランダムに画像を平行移動させる確率 | 0.0 | \n",
        "| scale          | ランダムに画像をスケールアップしてくり抜く確率 | 0.0 | \n",
        "| shear          | ランダムに画像をせん断写像変換する確率 | 0.0 | \n",
        "| perspective    | ランダムに画像をアフィン変換する確率| 0.0 | \n",
        "| flipud         | ランダムに上下反転させる確率 | 0.0 | \n",
        "| fliplr         | ランダムに左右反転させる確率 | 0.0 | \n",
        "| mosaic         | 複数の画像を組み合わせる | 1.0 | \n",
        "| mixup          | 画像を重ね合わせる | 0.1 | \n",
        "| copy_paste     | 画像を切り貼りする | 0.0 | \n",
        "| paste_in       | 画像を切り貼りする | 0.05 | \n",
        "| loss_ota       |ComputeLossOTAを使うかどうか| 1 | \n",
        "\n",
        "\n",
        "![img](https://user-images.githubusercontent.com/26833433/120995721-f3cfed00-c785-11eb-8ee2-b6ef2fa205e8.jpg)"
      ],
      "metadata": {
        "id": "XVbtICn0Gu36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov7/train.py --workers 2 \\\n",
        "  --data '/content/drive/MyDrive/Colab Notebooks/MetaW/YOLO_TRAIN/ocr_model.yaml' \\\n",
        "  --cfg yolov7/cfg/training/yolov7-tiny.yaml \\\n",
        "  --weights /content/yolov7/checkpoints/yolov7-tiny.pt \\\n",
        "  --img 2560 2560 \\\n",
        "  --name yolov7-tiny-model \\\n",
        "  --cache-images \\\n",
        "  --hyp '/content/drive/MyDrive/Colab Notebooks/MetaW/YOLO_TRAIN/hyp.scratch.tiny.yaml' \\\n",
        "  --epochs 100 \\\n",
        "  --project '/content/drive/MyDrive/Colab Notebooks/MetaW/YOLO_TRAIN/runs' \\\n",
        "  --device 0 \\"
      ],
      "metadata": {
        "id": "YdDc6sH_aSJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# 4.ONNX への出力"
      ],
      "metadata": {
        "id": "TMpun2cAXbdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx==1.13.0  # ONNX export\n",
        "!pip install onnx-simplifier\n",
        "!pip install nvidia-pyindex\n",
        "!pip install onnx-graphsurgeon\n",
        "!pip install onnxruntime"
      ],
      "metadata": {
        "id": "SV2kqGgyeG7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "次のコマンドでONNXに変換する\n",
        "```\n",
        "!python yolov7/export.py \\ #以下各種オプション\n",
        "  --weights ～ \\\n",
        "      ：\n",
        "      ： \n",
        "```\n",
        "\n",
        "\n",
        "各オプションの解説\n",
        "\n",
        "| オプション  | 説明 | デフォルト値 |必要かどうか | \n",
        "| ------      | -------- | ---- | ---- |\n",
        "| weights     | 変換するweightsのパス |  ./yolor-csp-c.pt | ○ | \n",
        "| img-size    | 画像のサイズ(height, width) | [640, 640] | ○ | \n",
        "| batch-size  | バッチサイズ | 1 |  | \n",
        "| dynamic     | 入力画像のサイズを可変にする場合、True | False |  | \n",
        "| dynamic-batch | 入力画像のサイズを可変 + バッチ処理する場合、True | False |  | \n",
        "| grid        | export Detect() layer grid (不明） | False | ○ | \n",
        "| end2end     | end2endにして出力するかどうか | False | ○ | \n",
        "| max-wh      | 最大の入力画像サイズ (int) | None |  | \n",
        "| topk-all*    | NMSの後に残すべき最適な検出の数 | 100 |  | \n",
        "| iou-thres*   | IoU のスカラー閾値 (以前に選択されたボックスと高い IOU  | 0.45 | ○ | \n",
        "|  | を持つ新しいボックスは削除される)  |  | | \n",
        "| conf-thres*  | スコアのスカラー閾値 (低スコアの箱は除去される) | 0.25 | ○ | \n",
        "| device      | 推論をするデバイス | cpu | | \n",
        "| simplify    | モデルを簡素化するかどうか（サイズが小さくなる)  | False |○ | \n",
        "|  | [onnx-simplifier](https://github.com/daquexian/onnx-simplifier)  |  | | \n",
        "| include-nms* | nmsを含めてエクスポートするかどうか | False |○ | \n",
        "\n",
        "\n",
        "---\n",
        "NMS: Non-Maximum Suppression\n",
        "\n",
        "> 画像中の物体を検出する際に発生しうる冗長なバウンディングボックスを除去するための手法\n",
        "\n",
        "\n",
        "具体的な流れ\n",
        "\n",
        "1.   `conf_threshold` よりも小さいバウンディングボックスを削除\n",
        "\n",
        "2.   `iou_threshold` よりも大きいIoUを持つスコアの低いボックスを別の (スコアの高い) ボックスで繰り返し削除\n",
        "\n",
        "3.   すべてのバウンディングボックスのIoUが`iou_threshold`以下になれば終了\n",
        "\n",
        "![image](https://wikidocs.net/images/page/142645/NMS.png\n",
        ")"
      ],
      "metadata": {
        "id": "WvlvslcbXnKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov7/export.py --grid \\\n",
        "  --weights '/content/drive/MyDrive/Colab Notebooks/MetaW/YOLO_TRAIN/runs/yolov7-tiny-model12/weights/best.pt' \\\n",
        "  --simplify \\\n",
        "  --end2end \\\n",
        "  --topk-all 100 \\\n",
        "  --iou-thres 0.6 \\\n",
        "  --conf-thres 0.3 \\\n",
        "  --img-size 640 640 \\\n",
        "  --max-wh 640 \\\n",
        "  --fp16"
      ],
      "metadata": {
        "id": "owSdQpIAXjlZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}